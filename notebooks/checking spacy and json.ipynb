{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import spacy\n",
    "from spacy.gold import biluo_tags_from_offsets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "nlp = spacy.load('en_core_web_sm')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I will first read the data nd then convert it into spacy format. After that I will extract BILOU tags from it and then convert it in to specific format required by flair"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "y1, y2 = 150, 160\n",
    "x1, x2 = 145, 160"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x1<=y2 and y1<=x2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "x1, x2 = 150, 160\n",
    "y1, y2 = 145, 149"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from flair.data import Sentence\n",
    "from flair.models import SequenceTagger\n",
    "import spacy\n",
    "from spacy.gold import biluo_tags_from_offsets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2020-01-18 18:17:48,886 loading file C:\\Users\\hp\\.flair\\models\\en-ner-conll03-v0.4.pt\n",
      "I love Berlin! <S-PER>\n",
      "TAGS->>>>>>>>>>>.. ['O', 'O', 'B-PERSON', 'L-PERSON', 'O']\n"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "'spacy.tokens.doc.Doc' object has no attribute 'tags'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-16-5d940c4e6ce7>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     20\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     21\u001b[0m \u001b[1;32mif\u001b[0m \u001b[0m__name__\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;34m'__main__'\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 22\u001b[1;33m     \u001b[0mcheck_ner\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m<ipython-input-16-5d940c4e6ce7>\u001b[0m in \u001b[0;36mcheck_ner\u001b[1;34m()\u001b[0m\n\u001b[0;32m     17\u001b[0m         \u001b[0mtags\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mbiluo_tags_from_offsets\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdoc\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mannot\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'entities'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     18\u001b[0m         \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"TAGS->>>>>>>>>>>..\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtags\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 19\u001b[1;33m         \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"TEXT->>>>>>>>>>\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdoc\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtags\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     20\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     21\u001b[0m \u001b[1;32mif\u001b[0m \u001b[0m__name__\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;34m'__main__'\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mAttributeError\u001b[0m: 'spacy.tokens.doc.Doc' object has no attribute 'tags'"
     ]
    }
   ],
   "source": [
    "def check_ner():\n",
    "    tagger = SequenceTagger.load('ner')\n",
    "    sentence = Sentence('I love Berlin!')\n",
    "    tagger.predict(sentence)\n",
    "    print(sentence.to_tagged_string())\n",
    "\n",
    "\n",
    "    TRAIN_DATA = [\n",
    "        (\"Who is Shaka Khan?\", {\"entities\": [(7, 17, \"PERSON\")]}),\n",
    "        (\"I like London and Berlin.\", {\"entities\": [(7, 13, \"LOCSEX\"), (18, 24, \"LOCSEX\")]}),\n",
    "    ]\n",
    "\n",
    "    nlp = spacy.load('en_core_web_sm')\n",
    "    docs = []\n",
    "    for text, annot in TRAIN_DATA:\n",
    "        doc = nlp(text)\n",
    "        tags = biluo_tags_from_offsets(doc, annot['entities'])\n",
    "        print(\"TAGS->>>>>>>>>>>..\", tags)\n",
    "        print(\"TEXT->>>>>>>>>>\", doc.)\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    check_ner()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TAGS->>>>>>>>>>>.. ['O', 'O', 'B-PERSON', 'L-PERSON', 'O']\n",
      "TEXT->>>>>>>>>> ['Who', 'is', 'Shaka', 'Khan', '?']\n",
      "TAGS->>>>>>>>>>>.. ['O', 'O', 'U-LOCSEX', 'O', 'U-LOCSEX', 'O']\n",
      "TEXT->>>>>>>>>> ['I', 'like', 'London', 'and', 'Berlin', '.']\n"
     ]
    }
   ],
   "source": [
    "TRAIN_DATA = [\n",
    "    (\"Who is Shaka Khan?\", {\"entities\": [(7, 17, \"PERSON\")]}),\n",
    "    (\"I like London and Berlin.\", {\"entities\": [(7, 13, \"LOCSEX\"), (18, 24, \"LOCSEX\")]}),\n",
    "]\n",
    "\n",
    "nlp = spacy.load('en_core_web_sm')\n",
    "docs = []\n",
    "\n",
    "for text, annot in TRAIN_DATA:\n",
    "    tokens = []\n",
    "    doc = nlp(text)\n",
    "    tags = biluo_tags_from_offsets(doc, annot['entities'])\n",
    "    for token in doc:\n",
    "        tokens.append(token.text)\n",
    "    print(\"TAGS->>>>>>>>>>>..\", tags)\n",
    "    print(\"TEXT->>>>>>>>>>\", tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "tags = ['O', 'O', 'O', 'O', 'U-protein', 'O', 'O', 'O', 'O', 'O', 'O', 'B-assay', 'I-assay', 'I-assay', 'I-assay', 'L-assay', 'O', 'O', 'O', 'B-experimental-construct', 'I-experimental-construct', 'I-experimental-construct', 'I-experimental-construct', 'L-experimental-construct', 'O', 'O', 'O', 'O', 'O', 'O', 'U-chemical', 'O', 'O', 'O', 'O', 'O', 'O', 'O']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_tags = []\n",
    "for tag in tags:\n",
    "    if tag[0]==\"U\":\n",
    "        new_tags.append(\"B\"+tag[1:])\n",
    "    elif tag[0]==\"L\":\n",
    "        new_tags.append(\"I\"+tag[1:])\n",
    "    else:\n",
    "        new_tags.append(tag)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['O',\n",
       " 'O',\n",
       " 'O',\n",
       " 'O',\n",
       " 'B-protein',\n",
       " 'O',\n",
       " 'O',\n",
       " 'O',\n",
       " 'O',\n",
       " 'O',\n",
       " 'O',\n",
       " 'B-assay',\n",
       " 'I-assay',\n",
       " 'I-assay',\n",
       " 'I-assay',\n",
       " 'I-assay',\n",
       " 'O',\n",
       " 'O',\n",
       " 'O',\n",
       " 'B-experimental-construct',\n",
       " 'I-experimental-construct',\n",
       " 'I-experimental-construct',\n",
       " 'I-experimental-construct',\n",
       " 'I-experimental-construct',\n",
       " 'O',\n",
       " 'O',\n",
       " 'O',\n",
       " 'O',\n",
       " 'O',\n",
       " 'O',\n",
       " 'B-chemical',\n",
       " 'O',\n",
       " 'O',\n",
       " 'O',\n",
       " 'O',\n",
       " 'O',\n",
       " 'O',\n",
       " 'O']"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "new_tags"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "docs = [([\"Abhinav\", \"Bhatt\", \",\", \"lamp\"], [\"name\", \"name\", \"O\", \"O\"]), ([\"Najsgd\", \"Shweta\", \"Anil\"], [\"name\", \"Date\", \"O\"])]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Abhinav', 'Bhatt', ',', 'lamp'] ['name', 'name', 'O', 'O']\n",
      "['Najsgd', 'Shweta', 'Anil'] ['name', 'Date', 'O']\n"
     ]
    }
   ],
   "source": [
    "for doc in docs:\n",
    "    print(doc[0], doc[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"file.txt\", \"w\") as file:\n",
    "    for doc in docs:\n",
    "        for name, label in zip(doc[0], doc[1]):\n",
    "            file.write(name+\" \"+label+\"\\n\")\n",
    "        file.write(\"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import spacy\n",
    "from spacy.tokenizer import Tokenizer\n",
    "from spacy.util import compile_prefix_regex, compile_infix_regex, compile_suffix_regex"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Note',\n",
       " ':',\n",
       " 'Since',\n",
       " 'the',\n",
       " 'fourteenth',\n",
       " 'century',\n",
       " 'the',\n",
       " 'practice',\n",
       " 'of',\n",
       " '“',\n",
       " 'medicine',\n",
       " '”',\n",
       " 'has',\n",
       " 'become',\n",
       " 'a',\n",
       " 'profession',\n",
       " ';',\n",
       " 'and',\n",
       " 'more',\n",
       " 'importantly',\n",
       " ',',\n",
       " 'it',\n",
       " \"'s\",\n",
       " 'a',\n",
       " 'male-dominated',\n",
       " 'profession',\n",
       " '.']"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def custom_tokenizer(nlp):\n",
    "    infix_re = re.compile(r'''[.\\,\\?\\:\\;\\...\\‘\\’\\`\\“\\”\\\"\\'~]''')\n",
    "    prefix_re = compile_prefix_regex(nlp.Defaults.prefixes)\n",
    "#     suffix_re = re.compile('…$|……$|,$|:$|;$|\\\\!$|\\\\?$|¿$|؟$|¡$|\\\\($|\\\\)$|\\\\[$|\\\\]$|\\\\{$|\\\\}$|<$|>$|_$|#$|\\\\*$|&$|。$|？$|！$|，$|、$|；$|：$|～$|·$|।$|،$|۔$|؛$|٪$|\\\\.\\\\.+$|…$|\\\\\\'$|\"$|”$|“$|`$|‘$|´$|’$|‚$|,$|„$|»$|«$|「$|」$|『$|』$|（$|）$|)\n",
    "    suffix_re = compile_suffix_regex(nlp.Defaults.suffixes)\n",
    "    return Tokenizer(nlp.vocab, prefix_search=prefix_re.search,\n",
    "                                suffix_search=suffix_re.search,\n",
    "                                infix_finditer=infix_re.finditer,\n",
    "                                token_match=None)\n",
    "\n",
    "nlp = spacy.load('en_core_web_sm')\n",
    "nlp.tokenizer = custom_tokenizer(nlp)\n",
    "\n",
    "doc = nlp(u'Note: Since the fourteenth century the practice of “medicine” has become a profession; and more importantly, it\\'s a male-dominated profession.')\n",
    "[token.text for token in doc]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['This', 'world', '(', 'is', ')', 'dange', 'CA2+', 'stuff', 'hyphen-comes', 'cant', \"'\", 't', 'do', 'this', 'tihing']\n"
     ]
    }
   ],
   "source": [
    "import re\n",
    "import spacy\n",
    "from spacy.tokenizer import Tokenizer\n",
    "\n",
    "prefix_re = re.compile(r'''^[[(\"']''')\n",
    "suffix_re = re.compile(r'''[])\"']$''')\n",
    "infix_re = re.compile(r'''[.\\,\\?\\:\\;\\...\\‘\\’\\`\\“\\”\\\"\\'~]''')\n",
    "# simple_url_re = re.compile(r'''[a-zA-Z0-9]/+''')\n",
    "\n",
    "def custom_tokenizer(nlp):\n",
    "    return Tokenizer(nlp.vocab,\n",
    "                                prefix_search=prefix_re.search,\n",
    "                                suffix_search=suffix_re.search,\n",
    "                                infix_finditer=infix_re.finditer)\n",
    "\n",
    "nlp = spacy.load(\"en_core_web_sm\")\n",
    "nlp.tokenizer = custom_tokenizer(nlp)\n",
    "doc = nlp(\"This world (is) dange CA2+ stuff hyphen-comes cant't do this tihing\")\n",
    "print([t.text for t in doc]) # ['hello', '-', 'world.', ':)']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['This',\n",
       " 'world',\n",
       " '(',\n",
       " 'is',\n",
       " ')',\n",
       " 'dange',\n",
       " 'CA2+',\n",
       " 'stuff',\n",
       " 'hyphen-comes',\n",
       " 'cant',\n",
       " \"'\",\n",
       " 't',\n",
       " 'do',\n",
       " 'this',\n",
       " 'tihing']"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "oc = nlp(\"Briefly, the oligonucleotide library was incubated with fusion proteins bound to either GST-coated bead-bound fusion proteins (GST-tag) or nickel/nitrilotriacetic acid matrix-bound fusion proteins (histidine-tag) in a buffer containing 20 mM Tris (pH 8.0), 50 mM KCl, 1 mM DTT, 0.5 mM EDTA, 10% glycerol, 20 μg/ml BSA, and 2 μg/ml poly(dI)⋅poly(dc).\")\n",
    "[token.text for token in doc]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['When',\n",
       " ' ',\n",
       " 'calmodulin',\n",
       " 'is',\n",
       " 'added',\n",
       " ',',\n",
       " 'the',\n",
       " 'inhibition',\n",
       " 'of',\n",
       " ' ',\n",
       " 'fascin-actin',\n",
       " 'interaction',\n",
       " 'by',\n",
       " ' ',\n",
       " 'caldesmon',\n",
       " 'and',\n",
       " ' ',\n",
       " 'TM',\n",
       " 'becomes',\n",
       " 'Ca2+',\n",
       " 'dependent',\n",
       " 'because',\n",
       " ' ',\n",
       " 'Ca2+/calmodulin',\n",
       " 'blocks',\n",
       " ' ',\n",
       " 'actin',\n",
       " 'binding',\n",
       " 'of',\n",
       " ' ',\n",
       " 'caldesmon',\n",
       " '.']"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "doc = nlp(\"When  calmodulin is added, the inhibition of  fascin-actin interaction by  caldesmon and  TM becomes Ca2+ dependent because  Ca2+/calmodulin blocks  actin binding of  caldesmon.\")\n",
    "[token.text for token in doc]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2020-01-19 23:56:59,703 Reading data from .\n",
      "2020-01-19 23:56:59,719 Train: file_train.txt\n",
      "2020-01-19 23:56:59,730 Dev: file_dev.txt\n",
      "2020-01-19 23:56:59,734 Test: None\n"
     ]
    }
   ],
   "source": [
    "from flair.data import Corpus\n",
    "from flair.datasets import ColumnCorpus\n",
    "\n",
    "# define columns\n",
    "columns = {0: 'text', 1: 'ner'}\n",
    "\n",
    "# this is the folder in which train, test and dev files reside\n",
    "data_folder = ''\n",
    "\n",
    "# init a corpus using column format, data folder and the names of the train, dev and test files\n",
    "corpus: Corpus = ColumnCorpus(data_folder, columns,\n",
    "                              train_file='file_train.txt',\n",
    "                             dev_file=\"file_dev.txt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "B , comparison of holo-Tf <B-protein> binding to neo <B-cell> , TfR1 <B-cell> , or TfR2-alpha <B-cell> cells <I-cell> .\n"
     ]
    }
   ],
   "source": [
    "print(corpus.train[0].to_tagged_string('ner'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from flair.data import Corpus\n",
    "# from flair.datasets import WNUT_17\n",
    "from flair.embeddings import TokenEmbeddings, WordEmbeddings, StackedEmbeddings, CharacterEmbeddings, FlairEmbeddings\n",
    "from typing import List"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Corpus: 1265 train + 201 dev + 140 test sentences\n"
     ]
    }
   ],
   "source": [
    "print(corpus)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\n",
      "    \"TRAIN\": {\n",
      "        \"dataset\": \"TRAIN\",\n",
      "        \"total_number_of_documents\": 1265,\n",
      "        \"number_of_documents_per_class\": {},\n",
      "        \"number_of_tokens_per_tag\": {},\n",
      "        \"number_of_tokens\": {\n",
      "            \"total\": 39382,\n",
      "            \"min\": 4,\n",
      "            \"max\": 154,\n",
      "            \"avg\": 31.13201581027668\n",
      "        }\n",
      "    },\n",
      "    \"TEST\": {\n",
      "        \"dataset\": \"TEST\",\n",
      "        \"total_number_of_documents\": 140,\n",
      "        \"number_of_documents_per_class\": {},\n",
      "        \"number_of_tokens_per_tag\": {},\n",
      "        \"number_of_tokens\": {\n",
      "            \"total\": 4231,\n",
      "            \"min\": 3,\n",
      "            \"max\": 68,\n",
      "            \"avg\": 30.22142857142857\n",
      "        }\n",
      "    },\n",
      "    \"DEV\": {\n",
      "        \"dataset\": \"DEV\",\n",
      "        \"total_number_of_documents\": 201,\n",
      "        \"number_of_documents_per_class\": {},\n",
      "        \"number_of_tokens_per_tag\": {},\n",
      "        \"number_of_tokens\": {\n",
      "            \"total\": 5987,\n",
      "            \"min\": 5,\n",
      "            \"max\": 112,\n",
      "            \"avg\": 29.786069651741293\n",
      "        }\n",
      "    }\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "print(corpus.obtain_statistics())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "B , comparison of holo-Tf <B-protein> binding to neo <B-cell> , TfR1 <B-cell> , or TfR2-alpha <B-cell> cells <I-cell> .\n",
      "B , comparison of holo-Tf binding to neo , TfR1 , or TfR2-alpha cells .\n"
     ]
    }
   ],
   "source": [
    "print(corpus.train[0].to_tagged_string('ner'))\n",
    "print(corpus.train[0].to_tagged_string('pos'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[b'<unk>', b'O', b'B-protein', b'B-cell', b'I-cell', b'B-protein-complex', b'I-protein-complex', b'B-DNA', b'B-protein-domain', b'I-protein-domain', b'-', b'B-chemical', b'B-assay', b'B-protein-family', b'I-protein-family', b'I-DNA', b'I-protein', b'B-amino-acid', b'B-fusion-protein', b'B-protein-motif', b'I-protein-motif', b'B-experimental-construct', b'I-experimental-construct', b'B-protein-region', b'I-protein-region', b'B-experiment-tag', b'B-RNA', b'B-protein-isoform', b'I-protein-isoform', b'I-chemical', b'B-peptide', b'B-tissue', b'I-tissue', b'B-parameter', b'B-process', b'I-process', b'I-RNA', b'B-reagent', b'I-reagent', b'I-assay', b'B-protein-DNA-complex', b'I-experiment-tag', b'B-disease', b'B-protein-RNA-complex', b'I-protein-RNA-complex', b'B-gene', b'B-drug', b'B-organelle', b'B-mutation', b'I-amino-acid', b'I-mutation', b'I-gene', b'I-organelle', b'I-drug', b'I-fusion-protein', b'B-organism', b'I-organism', b'B-RNA-family', b'I-peptide', b'I-protein-DNA-complex', b'B-brand', b'I-brand', b'I-disease', b'<START>', b'<STOP>']\n"
     ]
    }
   ],
   "source": [
    "tag_type = 'ner'\n",
    "\n",
    "# 3. make the tag dictionary from the corpus\n",
    "tag_dictionary = corpus.make_tag_dictionary(tag_type=tag_type)\n",
    "print(tag_dictionary.idx2item)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "65\n"
     ]
    }
   ],
   "source": [
    "print(len(tag_dictionary.idx2item))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "embedding_types: List[TokenEmbeddings] = [\n",
    "\n",
    "#     WordEmbeddings('glove'),\n",
    "\n",
    "    # comment in this line to use character embeddings\n",
    "#     CharacterEmbeddings(),\n",
    "\n",
    "    # comment in these lines to use flair embeddings\n",
    "    FlairEmbeddings('news-forward'),\n",
    "#     FlairEmbeddings('news-backward'),\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "embeddings: StackedEmbeddings = StackedEmbeddings(embeddings=embedding_types)\n",
    "\n",
    "# 5. initialize sequence tagger\n",
    "from flair.models import SequenceTagger\n",
    "\n",
    "tagger: SequenceTagger = SequenceTagger(hidden_size=256,\n",
    "                                        embeddings=embeddings,\n",
    "                                        tag_dictionary=tag_dictionary,\n",
    "                                        tag_type=tag_type,\n",
    "                                        use_crf=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2020-01-20 00:25:48,676 ----------------------------------------------------------------------------------------------------\n",
      "2020-01-20 00:25:48,684 Model: \"SequenceTagger(\n",
      "  (embeddings): StackedEmbeddings(\n",
      "    (list_embedding_0): FlairEmbeddings(\n",
      "      (lm): LanguageModel(\n",
      "        (drop): Dropout(p=0.05, inplace=False)\n",
      "        (encoder): Embedding(300, 100)\n",
      "        (rnn): LSTM(100, 2048)\n",
      "        (decoder): Linear(in_features=2048, out_features=300, bias=True)\n",
      "      )\n",
      "    )\n",
      "  )\n",
      "  (word_dropout): WordDropout(p=0.05)\n",
      "  (locked_dropout): LockedDropout(p=0.5)\n",
      "  (embedding2nn): Linear(in_features=2048, out_features=2048, bias=True)\n",
      "  (rnn): LSTM(2048, 256, batch_first=True, bidirectional=True)\n",
      "  (linear): Linear(in_features=512, out_features=65, bias=True)\n",
      ")\"\n",
      "2020-01-20 00:25:48,692 ----------------------------------------------------------------------------------------------------\n",
      "2020-01-20 00:25:48,696 Corpus: \"Corpus: 1265 train + 201 dev + 140 test sentences\"\n",
      "2020-01-20 00:25:48,705 ----------------------------------------------------------------------------------------------------\n",
      "2020-01-20 00:25:48,711 Parameters:\n",
      "2020-01-20 00:25:48,717  - learning_rate: \"0.01\"\n",
      "2020-01-20 00:25:48,719  - mini_batch_size: \"32\"\n",
      "2020-01-20 00:25:48,727  - patience: \"3\"\n",
      "2020-01-20 00:25:48,731  - anneal_factor: \"0.5\"\n",
      "2020-01-20 00:25:48,739  - max_epochs: \"10\"\n",
      "2020-01-20 00:25:48,743  - shuffle: \"True\"\n",
      "2020-01-20 00:25:48,747  - train_with_dev: \"False\"\n",
      "2020-01-20 00:25:48,751  - batch_growth_annealing: \"False\"\n",
      "2020-01-20 00:25:48,755 ----------------------------------------------------------------------------------------------------\n",
      "2020-01-20 00:25:48,759 Model training base path: \".\"\n",
      "2020-01-20 00:25:48,763 ----------------------------------------------------------------------------------------------------\n",
      "2020-01-20 00:25:48,771 Device: cpu\n",
      "2020-01-20 00:25:48,775 ----------------------------------------------------------------------------------------------------\n",
      "2020-01-20 00:25:48,779 Embeddings storage mode: cpu\n",
      "2020-01-20 00:25:48,791 ----------------------------------------------------------------------------------------------------\n",
      "2020-01-20 00:26:10,374 ----------------------------------------------------------------------------------------------------\n",
      "2020-01-20 00:26:10,377 Exiting from training early.\n",
      "2020-01-20 00:26:10,379 Saving model ...\n",
      "2020-01-20 00:26:11,461 Done.\n",
      "2020-01-20 00:26:11,468 ----------------------------------------------------------------------------------------------------\n",
      "2020-01-20 00:26:11,474 Testing using best model ...\n",
      "2020-01-20 00:26:11,480 loading file best-model.pt\n",
      "2020-01-20 00:26:21,142 0.2398\t0.0825\t0.1228\n",
      "2020-01-20 00:26:21,146 \n",
      "MICRO_AVG: acc 0.0654 - f1-score 0.1228\n",
      "MACRO_AVG: acc 0.0046 - f1-score 0.008150000000000001\n",
      "-          tp: 0 - fp: 0 - fn: 35 - tn: 0 - precision: 0.0000 - recall: 0.0000 - accuracy: 0.0000 - f1-score: 0.0000\n",
      "DNA        tp: 0 - fp: 0 - fn: 30 - tn: 0 - precision: 0.0000 - recall: 0.0000 - accuracy: 0.0000 - f1-score: 0.0000\n",
      "RNA        tp: 0 - fp: 0 - fn: 10 - tn: 0 - precision: 0.0000 - recall: 0.0000 - accuracy: 0.0000 - f1-score: 0.0000\n",
      "amino-acid tp: 0 - fp: 0 - fn: 5 - tn: 0 - precision: 0.0000 - recall: 0.0000 - accuracy: 0.0000 - f1-score: 0.0000\n",
      "assay      tp: 0 - fp: 0 - fn: 3 - tn: 0 - precision: 0.0000 - recall: 0.0000 - accuracy: 0.0000 - f1-score: 0.0000\n",
      "brand      tp: 0 - fp: 0 - fn: 1 - tn: 0 - precision: 0.0000 - recall: 0.0000 - accuracy: 0.0000 - f1-score: 0.0000\n",
      "cell       tp: 0 - fp: 0 - fn: 10 - tn: 0 - precision: 0.0000 - recall: 0.0000 - accuracy: 0.0000 - f1-score: 0.0000\n",
      "chemical   tp: 0 - fp: 0 - fn: 39 - tn: 0 - precision: 0.0000 - recall: 0.0000 - accuracy: 0.0000 - f1-score: 0.0000\n",
      "drug       tp: 0 - fp: 0 - fn: 3 - tn: 0 - precision: 0.0000 - recall: 0.0000 - accuracy: 0.0000 - f1-score: 0.0000\n",
      "experiment-tag tp: 0 - fp: 0 - fn: 3 - tn: 0 - precision: 0.0000 - recall: 0.0000 - accuracy: 0.0000 - f1-score: 0.0000\n",
      "experimental-construct tp: 0 - fp: 0 - fn: 6 - tn: 0 - precision: 0.0000 - recall: 0.0000 - accuracy: 0.0000 - f1-score: 0.0000\n",
      "fusion-protein tp: 0 - fp: 0 - fn: 3 - tn: 0 - precision: 0.0000 - recall: 0.0000 - accuracy: 0.0000 - f1-score: 0.0000\n",
      "gene       tp: 0 - fp: 0 - fn: 2 - tn: 0 - precision: 0.0000 - recall: 0.0000 - accuracy: 0.0000 - f1-score: 0.0000\n",
      "mutation   tp: 0 - fp: 0 - fn: 2 - tn: 0 - precision: 0.0000 - recall: 0.0000 - accuracy: 0.0000 - f1-score: 0.0000\n",
      "organelle  tp: 0 - fp: 0 - fn: 1 - tn: 0 - precision: 0.0000 - recall: 0.0000 - accuracy: 0.0000 - f1-score: 0.0000\n",
      "peptide    tp: 0 - fp: 0 - fn: 2 - tn: 0 - precision: 0.0000 - recall: 0.0000 - accuracy: 0.0000 - f1-score: 0.0000\n",
      "process    tp: 0 - fp: 0 - fn: 2 - tn: 0 - precision: 0.0000 - recall: 0.0000 - accuracy: 0.0000 - f1-score: 0.0000\n",
      "protein    tp: 41 - fp: 130 - fn: 175 - tn: 41 - precision: 0.2398 - recall: 0.1898 - accuracy: 0.1185 - f1-score: 0.2119\n",
      "protein-RNA-complex tp: 0 - fp: 0 - fn: 2 - tn: 0 - precision: 0.0000 - recall: 0.0000 - accuracy: 0.0000 - f1-score: 0.0000\n",
      "protein-complex tp: 0 - fp: 0 - fn: 27 - tn: 0 - precision: 0.0000 - recall: 0.0000 - accuracy: 0.0000 - f1-score: 0.0000\n",
      "protein-domain tp: 0 - fp: 0 - fn: 13 - tn: 0 - precision: 0.0000 - recall: 0.0000 - accuracy: 0.0000 - f1-score: 0.0000\n",
      "protein-family tp: 0 - fp: 0 - fn: 59 - tn: 0 - precision: 0.0000 - recall: 0.0000 - accuracy: 0.0000 - f1-score: 0.0000\n",
      "protein-isoform tp: 0 - fp: 0 - fn: 1 - tn: 0 - precision: 0.0000 - recall: 0.0000 - accuracy: 0.0000 - f1-score: 0.0000\n",
      "protein-motif tp: 0 - fp: 0 - fn: 6 - tn: 0 - precision: 0.0000 - recall: 0.0000 - accuracy: 0.0000 - f1-score: 0.0000\n",
      "protein-region tp: 0 - fp: 0 - fn: 5 - tn: 0 - precision: 0.0000 - recall: 0.0000 - accuracy: 0.0000 - f1-score: 0.0000\n",
      "reagent    tp: 0 - fp: 0 - fn: 11 - tn: 0 - precision: 0.0000 - recall: 0.0000 - accuracy: 0.0000 - f1-score: 0.0000\n",
      "2020-01-20 00:26:21,149 ----------------------------------------------------------------------------------------------------\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'test_score': 0.1228,\n",
       " 'dev_score_history': [],\n",
       " 'train_loss_history': [],\n",
       " 'dev_loss_history': []}"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from flair.trainers import ModelTrainer\n",
    "\n",
    "trainer: ModelTrainer = ModelTrainer(tagger, corpus)\n",
    "\n",
    "# 7. start training\n",
    "trainer.train('',\n",
    "              learning_rate=0.01,\n",
    "              mini_batch_size=32,\n",
    "              max_epochs=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "ename": "UnboundLocalError",
     "evalue": "local variable 'figsize' referenced before assignment",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mUnboundLocalError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-22-4891ef54a7f0>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mflair\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mvisual\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtraining_curves\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mPlotter\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[0mplotter\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mPlotter\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 4\u001b[1;33m \u001b[0mplotter\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mplot_weights\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'weights.txt'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32mc:\\users\\hp\\.conda\\envs\\.enc\\lib\\site-packages\\flair\\visual\\training_curves.py\u001b[0m in \u001b[0;36mplot_weights\u001b[1;34m(self, file_name)\u001b[0m\n\u001b[0;32m    143\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    144\u001b[0m         \u001b[0mfig\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mplt\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfigure\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 145\u001b[1;33m         \u001b[0mf\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0maxarr\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mplt\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msubplots\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mrows\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcolumns\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfigsize\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mfigsize\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    146\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    147\u001b[0m         \u001b[0mc\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mUnboundLocalError\u001b[0m: local variable 'figsize' referenced before assignment"
     ]
    }
   ],
   "source": [
    "# 8. plot weight traces (optional)\n",
    "from flair.visual.training_curves import Plotter\n",
    "plotter = Plotter()\n",
    "plotter.plot_weights('weights.txt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2020-01-19 11:08:29,817 loading file final-model.pt\n",
      "Sam Houston stayed home. <B-PER>\n"
     ]
    }
   ],
   "source": [
    "# load the model you trained\n",
    "from flair.data import Sentence\n",
    "\n",
    "model = SequenceTagger.load('final-model.pt')\n",
    "\n",
    "# create example sentence\n",
    "sentence = Sentence(\"Sam Houston stayed home.\")\n",
    "\n",
    "# predict tags and print\n",
    "model.predict(sentence)\n",
    "\n",
    "print(sentence.to_tagged_string())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
