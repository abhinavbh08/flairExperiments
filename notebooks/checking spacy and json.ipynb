{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import spacy\n",
    "from spacy.gold import biluo_tags_from_offsets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "nlp = spacy.load('en_core_web_sm')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I will first read the data nd then convert it into spacy format. After that I will extract BILOU tags from it and then convert it in to specific format required by flair"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "y1, y2 = 150, 160\n",
    "x1, x2 = 145, 160"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x1<=y2 and y1<=x2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "x1, x2 = 150, 160\n",
    "y1, y2 = 145, 149"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from flair.data import Sentence\n",
    "from flair.models import SequenceTagger\n",
    "import spacy\n",
    "from spacy.gold import biluo_tags_from_offsets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2020-01-18 18:17:48,886 loading file C:\\Users\\hp\\.flair\\models\\en-ner-conll03-v0.4.pt\n",
      "I love Berlin! <S-PER>\n",
      "TAGS->>>>>>>>>>>.. ['O', 'O', 'B-PERSON', 'L-PERSON', 'O']\n"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "'spacy.tokens.doc.Doc' object has no attribute 'tags'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-16-5d940c4e6ce7>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     20\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     21\u001b[0m \u001b[1;32mif\u001b[0m \u001b[0m__name__\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;34m'__main__'\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 22\u001b[1;33m     \u001b[0mcheck_ner\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m<ipython-input-16-5d940c4e6ce7>\u001b[0m in \u001b[0;36mcheck_ner\u001b[1;34m()\u001b[0m\n\u001b[0;32m     17\u001b[0m         \u001b[0mtags\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mbiluo_tags_from_offsets\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdoc\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mannot\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'entities'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     18\u001b[0m         \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"TAGS->>>>>>>>>>>..\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtags\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 19\u001b[1;33m         \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"TEXT->>>>>>>>>>\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdoc\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtags\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     20\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     21\u001b[0m \u001b[1;32mif\u001b[0m \u001b[0m__name__\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;34m'__main__'\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mAttributeError\u001b[0m: 'spacy.tokens.doc.Doc' object has no attribute 'tags'"
     ]
    }
   ],
   "source": [
    "def check_ner():\n",
    "    tagger = SequenceTagger.load('ner')\n",
    "    sentence = Sentence('I love Berlin!')\n",
    "    tagger.predict(sentence)\n",
    "    print(sentence.to_tagged_string())\n",
    "\n",
    "\n",
    "    TRAIN_DATA = [\n",
    "        (\"Who is Shaka Khan?\", {\"entities\": [(7, 17, \"PERSON\")]}),\n",
    "        (\"I like London and Berlin.\", {\"entities\": [(7, 13, \"LOCSEX\"), (18, 24, \"LOCSEX\")]}),\n",
    "    ]\n",
    "\n",
    "    nlp = spacy.load('en_core_web_sm')\n",
    "    docs = []\n",
    "    for text, annot in TRAIN_DATA:\n",
    "        doc = nlp(text)\n",
    "        tags = biluo_tags_from_offsets(doc, annot['entities'])\n",
    "        print(\"TAGS->>>>>>>>>>>..\", tags)\n",
    "        print(\"TEXT->>>>>>>>>>\", doc.)\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    check_ner()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TAGS->>>>>>>>>>>.. ['O', 'O', 'B-PERSON', 'L-PERSON', 'O']\n",
      "TEXT->>>>>>>>>> ['Who', 'is', 'Shaka', 'Khan', '?']\n",
      "TAGS->>>>>>>>>>>.. ['O', 'O', 'U-LOCSEX', 'O', 'U-LOCSEX', 'O']\n",
      "TEXT->>>>>>>>>> ['I', 'like', 'London', 'and', 'Berlin', '.']\n"
     ]
    }
   ],
   "source": [
    "TRAIN_DATA = [\n",
    "    (\"Who is Shaka Khan?\", {\"entities\": [(7, 17, \"PERSON\")]}),\n",
    "    (\"I like London and Berlin.\", {\"entities\": [(7, 13, \"LOCSEX\"), (18, 24, \"LOCSEX\")]}),\n",
    "]\n",
    "\n",
    "nlp = spacy.load('en_core_web_sm')\n",
    "docs = []\n",
    "\n",
    "for text, annot in TRAIN_DATA:\n",
    "    tokens = []\n",
    "    doc = nlp(text)\n",
    "    tags = biluo_tags_from_offsets(doc, annot['entities'])\n",
    "    for token in doc:\n",
    "        tokens.append(token.text)\n",
    "    print(\"TAGS->>>>>>>>>>>..\", tags)\n",
    "    print(\"TEXT->>>>>>>>>>\", tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "tags = ['O', 'O', 'O', 'O', 'U-protein', 'O', 'O', 'O', 'O', 'O', 'O', 'B-assay', 'I-assay', 'I-assay', 'I-assay', 'L-assay', 'O', 'O', 'O', 'B-experimental-construct', 'I-experimental-construct', 'I-experimental-construct', 'I-experimental-construct', 'L-experimental-construct', 'O', 'O', 'O', 'O', 'O', 'O', 'U-chemical', 'O', 'O', 'O', 'O', 'O', 'O', 'O']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_tags = []\n",
    "for tag in tags:\n",
    "    if tag[0]==\"U\":\n",
    "        new_tags.append(\"B\"+tag[1:])\n",
    "    elif tag[0]==\"L\":\n",
    "        new_tags.append(\"I\"+tag[1:])\n",
    "    else:\n",
    "        new_tags.append(tag)a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['O',\n",
       " 'O',\n",
       " 'O',\n",
       " 'O',\n",
       " 'B-protein',\n",
       " 'O',\n",
       " 'O',\n",
       " 'O',\n",
       " 'O',\n",
       " 'O',\n",
       " 'O',\n",
       " 'B-assay',\n",
       " 'I-assay',\n",
       " 'I-assay',\n",
       " 'I-assay',\n",
       " 'I-assay',\n",
       " 'O',\n",
       " 'O',\n",
       " 'O',\n",
       " 'B-experimental-construct',\n",
       " 'I-experimental-construct',\n",
       " 'I-experimental-construct',\n",
       " 'I-experimental-construct',\n",
       " 'I-experimental-construct',\n",
       " 'O',\n",
       " 'O',\n",
       " 'O',\n",
       " 'O',\n",
       " 'O',\n",
       " 'O',\n",
       " 'B-chemical',\n",
       " 'O',\n",
       " 'O',\n",
       " 'O',\n",
       " 'O',\n",
       " 'O',\n",
       " 'O',\n",
       " 'O']"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "new_tags\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "docs = [([\"Abhinav\", \"Bhatt\", \",\", \"lamp\"], [\"name\", \"name\", \"O\", \"O\"]), ([\"Najsgd\", \"Shweta\", \"Anil\"], [\"name\", \"Date\", \"O\"])]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Abhinav', 'Bhatt', ',', 'lamp'] ['name', 'name', 'O', 'O']\n",
      "['Najsgd', 'Shweta', 'Anil'] ['name', 'Date', 'O']\n"
     ]
    }
   ],
   "source": [
    "for doc in docs:\n",
    "    print(doc[0], doc[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"file.txt\", \"w\") as file:\n",
    "    for doc in docs:\n",
    "        for name, label in zip(doc[0], doc[1]):\n",
    "            file.write(name+\" \"+label+\"\\n\")\n",
    "        file.write(\"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
